{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./data.csv')\n",
    "\n",
    "data = data[~data['CustomerID'].isna()].reset_index(drop=True)\n",
    "print len(data)\n",
    "print data.keys()\n",
    "import matplotlib.pyplot as plt\n",
    "data['TotalRevenue'] = data['Quantity']*data['UnitPrice']/1#interpretation\n",
    "print data.iloc[5000:5005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data['Month'] = data['InvoiceDate'].apply(lambda x : x.split('/')[0]).astype(np.uint8)\n",
    "data['Day'] = data['InvoiceDate'].apply(lambda x : x.split('/')[1]).astype(np.uint8)\n",
    "data['Year'] = data['InvoiceDate'].apply(lambda x : x.split('/')[2].split(' ')[0]).astype(np.uint16)\n",
    "data['Time'] = data['InvoiceDate'].apply(lambda x : x.split('/')[2].split(' ')[1])\n",
    "data['Hour']= data['Time'].apply(lambda x : x.split(':')[0]).astype(np.uint8)\n",
    "data['Min']= data['Time'].apply(lambda x : x.split(':')[1]).astype(np.uint8)\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp = data.groupby(['CustomerID',])['TotalRevenue'].apply(sum).reset_index(drop=False)\n",
    "plt.hist(temp.TotalRevenue);plt.yscale('log');plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# different scales, from the following, hence use log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ignoring customers who causes losses because they are small portion of revenue\n",
    "bins=range(0,300001,50000)\n",
    "xx=plt.hist(temp['TotalRevenue'],bins=bins)\n",
    "print xx\n",
    "plt.close()\n",
    "plt.subplots(figsize=(10,10))\n",
    "xxx=plt.hist(temp['TotalRevenue'],weights = temp['TotalRevenue'].values/1000, bins=bins)\n",
    "for i in range(len(xxx[1])-1):\n",
    "    plt.text(xxx[1][i],xxx[0][i]+0.03,str(int(xx[0][i]))+' Customers',fontsize=12,fontweight='bold')\n",
    "plt.xticks(np.array(bins)+25000,['Spent\\n' + str(bins[x]/1000)+'k-'+str(bins[x+1]/1000)+'k' for x in  range(len(bins)-1)],rotation=60)\n",
    "plt.xlabel('Spending',fontsize=15,fontweight='bold')\n",
    "plt.ylabel('Contribution to Revenue in Millions',fontsize=15,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#combine certain stock types which are obviously simillar differetn colour t-shirts\n",
    "def f(x):\n",
    "    if  x[:-1].isdigit() and x[-1].isdigit() is False:\n",
    "        return x[:-1]\n",
    "    else : return x\n",
    "data['StockCode_NR'] = data['StockCode'].apply(f)\n",
    "\n",
    "#returns cost 0.1%, so ignore first\n",
    "data = data[data['TotalRevenue']>0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# are there any subgroups of important customer\n",
    "temp = data.groupby(['CustomerID',])['TotalRevenue'].apply(sum).reset_index(drop=False)\n",
    "temp2 = temp.sort_values('TotalRevenue').iloc[::-1].reset_index(drop=True)\n",
    "result,val = [] ,0\n",
    "for i in range(len(temp2)):\n",
    "    val += temp2.iloc[i]['TotalRevenue']\n",
    "    result += [val,]\n",
    "temp2['cummulative_profit'] = np.array(result)/val\n",
    "for i in [0.01,0.1,1,2,5,10,20,50]:\n",
    "    num = int(len(temp2)*1.*i/100)\n",
    "    print num,\n",
    "    print 'Top %s percent of customers,%s percent of profit'%(i,100*np.round(temp2.loc[num]['cummulative_profit'],2))\n",
    "plt.plot(temp2['cummulative_profit']);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# are there any subgroups of important customer\n",
    "temp = data.groupby(['StockCode_NR'])['TotalRevenue'].apply(sum).reset_index(drop=False)\n",
    "temp['totalRev_over_time'] = data.groupby(['StockCode_NR'])['TotalRevenue'].apply(np.sum).reset_index(drop=True)\n",
    "temp2 = temp.sort_values('totalRev_over_time').iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "result,val = [0,] ,0\n",
    "for i in range(len(temp2)):\n",
    "    val += temp2.iloc[i]['TotalRevenue']\n",
    "    result += [val,]\n",
    "temp2['cummulative_profit'] = np.array(result[1:])/val\n",
    "temp2['Total_profit'] = (np.array(result[1:])-np.array(result[:-1]))/val\n",
    "for i in [0.01,0.1,1,2,5,10,20,50,60]:\n",
    "    num = int(len(temp2)*1.*i/100)\n",
    "    print num,\n",
    "    print 'Top %s percent of products,%s percent of profit'%(i,100*np.round(temp2.loc[num]['cummulative_profit'],2))\n",
    "plt.plot(temp2['cummulative_profit']);plt.show()\n",
    "x = 10\n",
    "print np.sum(temp2['totalRev_over_time']>x)\n",
    "print 'threshold=',x,',',np.round(np.mean(temp2['totalRev_over_time']>x),2),'of products account for',\n",
    "print np.round(np.sum(temp2[temp2['totalRev_over_time']>x]['TotalRevenue'])/np.sum(temp2['TotalRevenue']),3),'of revenue\\n\\n'\n",
    "temp3 = temp2[temp2['totalRev_over_time']>x]\n",
    "data2 = pd.merge(data,temp3[['StockCode_NR','totalRev_over_time','Total_profit']]\n",
    "         ,on='StockCode_NR',how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info = data.groupby(['CustomerID',])['TotalRevenue'].apply(sum).reset_index(drop=False)\n",
    "customer_info = customer_info.sort_values('TotalRevenue').iloc[::-1].reset_index(drop=False)\n",
    "\n",
    "for year in pd.unique(data.Year):\n",
    "    for month in sorted(map(int,pd.unique(data.Month))):\n",
    "        temp0  =  data2[(data2.Year==year) & (data2.Month==month)]\n",
    "        if len(temp0) == 0:\n",
    "            continue\n",
    "        temp = temp0.groupby(['CustomerID',])['TotalRevenue'].apply(sum).reset_index(drop=False)\n",
    "        temp2 = temp.sort_values('TotalRevenue').iloc[::-1].reset_index(drop=True)\n",
    "        result,val = [] ,0\n",
    "        for i in range(len(temp2)):\n",
    "            val += temp2.iloc[i]['TotalRevenue']\n",
    "            result += [val,]\n",
    "        temp2['cummulative_profit'] = np.array(result)/val\n",
    "        temp2.rename(columns={'TotalRevenue' : 'Revenue_%s_%s'%(year,month)},inplace=True)\n",
    "        customer_info = pd.merge(customer_info,temp2[temp2.keys()[:2]],on='CustomerID',how='left').fillna(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dictt_StockCode = {}\n",
    "counter = 0\n",
    "for i in data2.groupby(['totalRev_over_time','StockCode_NR'])['TotalRevenue'].apply(sum).reset_index(drop=False)['StockCode_NR'].iloc[::-1]:\n",
    "    dictt_StockCode[i] = counter\n",
    "    counter += 1\n",
    "data2['StockCode_NR_int'] = data2['StockCode_NR'].map(dictt_StockCode)\n",
    "print counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = data2[((data2['Year']==2010)*(data2['Month'].isin([12,]))) | \\\n",
    "              ((data2['Year']==2011)*(data2['Month'].isin([1,2,3,4])))]\n",
    "test = data2[ ((data2['Year']==2011)*(data2['Month'].isin([5])))]\n",
    "test2 = data2[ ((data2['Year']==2011)*(data2['Month'].isin([6,])))]\n",
    "test3 = data2[ ((data2['Year']==2011)*(data2['Month'].isin([7,])))]\n",
    "test4 = data2[ ((data2['Year']==2011)*(data2['Month'].isin([6,7,])))]\n",
    "test5 = data2[ ((data2['Year']==2011)*(data2['Month'].isin([6,7,8,9,10,11])))]\n",
    "\n",
    "len(train),len(test),len(test2),len(test3),len(test4),len(test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get all orders from customer during time period \n",
    "Invoice = train.groupby(['CustomerID',]).apply(lambda x :(list(x['StockCode_NR_int']),\n",
    "                                                         list(x['Quantity']))).reset_index(drop=0)\n",
    "#print Invoice.head()\n",
    "customer_info_orders = pd.merge(customer_info,Invoice,on='CustomerID',how='outer')\n",
    "customer_info_orders.rename(columns={0 : 'orders'},inplace=True)\n",
    "\n",
    "Invoice_future = test.groupby(['CustomerID',]).apply(lambda x :(list(x['StockCode_NR_int']),\n",
    "                                                         list(x['Quantity']))).reset_index(drop=0)\n",
    "#print Invoice.head()\n",
    "customer_info_orders = pd.merge(customer_info_orders,Invoice_future,on='CustomerID',how='outer')\n",
    "customer_info_orders.rename(columns={0 : 'orders_future'},inplace=True)\n",
    "\n",
    "Invoice_future = test2.groupby(['CustomerID',]).apply(lambda x :(list(x['StockCode_NR_int']),\n",
    "                                                         list(x['Quantity']))).reset_index(drop=0)\n",
    "#print Invoice.head()\n",
    "customer_info_orders = pd.merge(customer_info_orders,Invoice_future,on='CustomerID',how='outer')\n",
    "customer_info_orders.rename(columns={0 : 'orders_future2'},inplace=True)\n",
    "\n",
    "Invoice_future = test3.groupby(['CustomerID',]).apply(lambda x :(list(x['StockCode_NR_int']),\n",
    "                                                         list(x['Quantity']))).reset_index(drop=0)\n",
    "#print Invoice.head()\n",
    "customer_info_orders = pd.merge(customer_info_orders,Invoice_future,on='CustomerID',how='outer')\n",
    "customer_info_orders.rename(columns={0 : 'orders_future3'},inplace=True)\n",
    "\n",
    "Invoice_future = test4.groupby(['CustomerID',]).apply(lambda x :(list(x['StockCode_NR_int']),\n",
    "                                                         list(x['Quantity']))).reset_index(drop=0)\n",
    "#print Invoice.head()\n",
    "customer_info_orders = pd.merge(customer_info_orders,Invoice_future,on='CustomerID',how='outer')\n",
    "customer_info_orders.rename(columns={0 : 'orders_future4'},inplace=True)\n",
    "\n",
    "Invoice_future = test5.groupby(['CustomerID',]).apply(lambda x :(list(x['StockCode_NR_int']),\n",
    "                                                         list(x['Quantity']))).reset_index(drop=0)\n",
    "#print Invoice.head()\n",
    "customer_info_orders = pd.merge(customer_info_orders,Invoice_future,on='CustomerID',how='outer')\n",
    "customer_info_orders.rename(columns={0 : 'orders_future5'},inplace=True)\n",
    "\n",
    "customer_info_orders = customer_info_orders.sort_values('CustomerID').reset_index(drop=True)\n",
    "#print customer_info_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matrix_past = np.zeros((len(customer_info_orders),counter)).astype(np.float32)\n",
    "for i in range(len(customer_info_orders)):\n",
    "    try:\n",
    "        pdt,quantity = customer_info_orders.iloc[i]['orders']\n",
    "        for j,k in zip(pdt,quantity):\n",
    "            matrix_past[i,j] += k\n",
    "    except TypeError : None #no orders presetn\n",
    "matrix_past = 1*(matrix_past>0)\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matrix_future = np.zeros((len(customer_info_orders),counter)).astype(np.float32)\n",
    "for i in range(len(customer_info_orders)):\n",
    "    try:\n",
    "        pdt,quantity = customer_info_orders.iloc[i]['orders_future']\n",
    "        for j,k in zip(pdt,quantity):\n",
    "            matrix_future[i,j] += k\n",
    "    except TypeError : None #no orders presetn\n",
    "\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matrix_future2 = np.zeros((len(customer_info_orders),counter)).astype(np.float32)\n",
    "for i in range(len(customer_info_orders)):\n",
    "    try:\n",
    "        pdt,quantity = customer_info_orders.iloc[i]['orders_future2']\n",
    "        for j,k in zip(pdt,quantity):\n",
    "            matrix_future2[i,j] += k\n",
    "    except TypeError : None #no orders presetn\n",
    "\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matrix_future3 = np.zeros((len(customer_info_orders),counter)).astype(np.float32)\n",
    "for i in range(len(customer_info_orders)):\n",
    "    try:\n",
    "        pdt,quantity = customer_info_orders.iloc[i]['orders_future3']\n",
    "        for j,k in zip(pdt,quantity):\n",
    "            matrix_future3[i,j] += k\n",
    "    except TypeError : None #no orders presetn\n",
    "\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matrix_future4 = np.zeros((len(customer_info_orders),counter)).astype(np.float32)\n",
    "for i in range(len(customer_info_orders)):\n",
    "    try:\n",
    "        pdt,quantity = customer_info_orders.iloc[i]['orders_future4']\n",
    "        for j,k in zip(pdt,quantity):\n",
    "            matrix_future4[i,j] += k\n",
    "    except TypeError : None #no orders presetn\n",
    "\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matrix_future5 = np.zeros((len(customer_info_orders),counter)).astype(np.float32)\n",
    "for i in range(len(customer_info_orders)):\n",
    "    try:\n",
    "        pdt,quantity = customer_info_orders.iloc[i]['orders_future5']\n",
    "        for j,k in zip(pdt,quantity):\n",
    "            matrix_future5[i,j] += k\n",
    "    except TypeError : None #no orders presetn\n",
    "\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# recommendation system , for our case since entries are small, we use SVD to do matrix factorization\n",
    "# instead of a less expensive but approximate algorithm like alternating last squares. WARNING This is not scalable. \n",
    "U,D,V = np.linalg.svd(matrix_past)\n",
    "print len(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "matrix_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num = 1000\n",
    "U2=U[:,:num]\n",
    "D2=D[:num]\n",
    "V2=V[:num]\n",
    "Z = sum(D)\n",
    "print sum(D2)/Z\n",
    "plt.plot(map(lambda x : np.sum(D[:x])/Z,range(len(D2))))\n",
    "plt.show()\n",
    "print matrix_past\n",
    "np.matmul(np.matmul(U2,np.diag(D2)),V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.matmul(np.matmul(U2,np.diag(D2**.5)),np.matmul(np.diag(D2**.5),V2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(counter):\n",
    "    customer_info_orders['pdt_'+str(i)] = matrix_past[:,i].astype(np.uint16)\n",
    "for i in range(U2.shape[1]):\n",
    "    customer_info_orders['svd_'+str(i)] = U2[:,i].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "colsA =  ['Revenue_2011_' + str(x) for x in [1,2,3,4]]+['Revenue_2010_12']\n",
    "#print np.corrcoef(customer_info_orders['target2'].values,\n",
    "#           np.mean(np.log10(1+customer_info_orders[colsA].values),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders.keys()[3:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SQUARED LOGLOSS\n",
    "#predict customer orders\n",
    "import xgboost as  xgb\n",
    "'''\n",
    "train = data2[((data2['Year']==2010)*(data2['Month'].isin([12,]))) | \\\n",
    "              ((data2['Year']==2011)*(data2['Month'].isin([1,2,3,4])))]\n",
    "test = data2[ ((data2['Year']==2011)*(data2['Month'].isin([5])))]\n",
    "test2 = data2[ ((data2['Year']==2011)*(data2['Month'].isin([6,])))]\n",
    "test3 = data2[ ((data2['Year']==2011)*(data2['Month'].isin([7,])))]\n",
    "test4 = data2[ ((data2['Year']==2011)*(data2['Month'].isin([6,7,])))]\n",
    "test5 = data2[ ((data2['Year']==2011)*(data2['Month'].isin([6,7,8,9,10,11])))]\n",
    "\n",
    "len(train),len(test),len(test2),len(test3),len(test4),len(test5)\n",
    "'''\n",
    "customer_info_orders.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in customer_info_orders.columns.values]\n",
    "\n",
    "predictors = list(customer_info_orders.keys()[3:8])+['mean_log_rev_train',]+\\\n",
    "                     list([x for x in customer_info_orders.keys() if 'svd' in str(x)]) [:30]\n",
    "colsA =  ['Revenue_2011_' + str(x) for x in [1,2,3,4]]+['Revenue_2010_12']\n",
    "customer_info_orders['mean_log_rev_train']= np.log10(1+np.mean(customer_info_orders[colsA].values,1))\n",
    "z = customer_info_orders[['pdt_'+str(x) for x in range(100)]].describe().loc['mean']\n",
    "predictors += list(z[z>0.03].index)\n",
    "target = 'target'\n",
    "gc.collect()\n",
    "for i in range(2,6):\n",
    "    cols = [[0,],[0,],[6,],[7,],[8,],[6,7,8]][i]\n",
    "    cols = ['Revenue_2011_'+str(x) for x in cols]\n",
    "    customer_info_orders[target+str(i)]= np.log10(1+np.mean(customer_info_orders[cols].values,1))\n",
    "\n",
    "\n",
    "if True:\n",
    "    customer_info_orders2 = customer_info_orders.copy()\n",
    "    customer_info_orders2 = customer_info_orders2[customer_info_orders2['mean_log_rev_train']>0] #remove datapoints which have not brought stuff\n",
    "    customer_info_orders2[target]= np.log10(1+np.mean(customer_info_orders2[['Revenue_2011_5',]].values,1))\n",
    "    train_id = [x for x in range(len(customer_info_orders2)) if x%5!=0]\n",
    "    test_id = [x for x in range(len(customer_info_orders2)) if x%5==0]\n",
    "    dtrain = customer_info_orders2.iloc[train_id]\n",
    "    dcv = customer_info_orders2.iloc[test_id]\n",
    "    dtest = customer_info_orders2\n",
    "    gc.collect()\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"\n",
    "    params[\"eta\"] = 0.01/10\n",
    "    params[\"min_child_weight\"] = 1\n",
    "    params[\"subsample\"] = 0.3\n",
    "    params[\"colsample_bytree\"] = 0.3\n",
    "    params[\"scale_pos_weight\"] = 1.0\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"verbose\"] = 1\n",
    "    params[\"max_depth\"] = 5\n",
    "    #params[\"nthread\"] = 6\n",
    "    params[\"nthread\"] = -1\n",
    "    early_stopping_rounds = 50\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "    xgcv = xgb.DMatrix(dcv[predictors].values, label=dcv[target].values)\n",
    "    xgtest2 = xgb.DMatrix(dtest[predictors].values, label=dtest[target+'2'].values)\n",
    "    xgtest3 = xgb.DMatrix(dtest[predictors].values, label=dtest[target+'3'].values)\n",
    "    xgtest4 = xgb.DMatrix(dtest[predictors].values, label=dtest[target+'4'].values)\n",
    "    xgtest5 = xgb.DMatrix(dtest[predictors].values, label=dtest[target+'5'].values)\n",
    "    #    xgb.train(xgtrain[predictors],dtrain['Demanda_uni_equil'],eval_set=evallist ,\n",
    "    #            eval_metric='rmse', early_stopping_rounds=early_stopping_rounds)\n",
    "    watchlist  = [ (xgtrain,'train'),(xgtest2,'2month'),(xgtest3,'3month'),\n",
    "                  (xgtest4,'4month'),(xgtest5,'5month'),(xgcv,'eval')][:]\n",
    "    a = {}\n",
    "    model=xgb.train(plst,xgtrain,10*5510,watchlist,verbose_eval =1000,feval=None,\n",
    "                    early_stopping_rounds=early_stopping_rounds*3,evals_result=a)\n",
    "    print np.corrcoef(np.nan_to_num(np.log10(model.predict(xgtest2)[test_id])),\n",
    "                      customer_info_orders2[target].iloc[test_id])\n",
    "    val = 0\n",
    "    for j in range(2,6):\n",
    "        j = str(j)\n",
    "        customer_info_orders2['pred'+j] = model.predict(xgtest2)\n",
    "        xxxx = np.corrcoef(model.predict(xgtest2),customer_info_orders2['target'+j])\n",
    "        val += xxxx[1,0]\n",
    "        print xxxx\n",
    "        \n",
    "    print val/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import xgbfir\n",
    "xgbfir.saveXgbFI(model,MaxTrees =1000,feature_names=predictors )\n",
    "xgb_explain = pd.read_excel('./XgbFeatureInteractions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print xgb_explain.sort_values('Gain').iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(customer_info_orders2['mean_log_rev_train'],customer_info_orders2['target5'],'ro',markersize=0.5)\n",
    "plt.xlabel('mean revenue from month 1-5',weight='bold',fontsize=12)\n",
    "plt.ylabel('mean revenue from month 7-12',weight='bold',fontsize=12)\n",
    "plt.title('Past revenue vs future revenue',weight='bold',fontsize=12)\n",
    "plt.xticks(range(5),[10**x for x in range(5)])\n",
    "plt.yticks(range(5),[10**x for x in range(5)])\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(np.log10(1+customer_info_orders2['Revenue_2011_3']),customer_info_orders2['target5'],'ro',markersize=0.5)\n",
    "plt.xlabel('mean revenue from month 3',weight='bold',fontsize=12)\n",
    "plt.ylabel('mean revenue from month 7-12',weight='bold',fontsize=12)\n",
    "plt.title('Month 4 vs future revenue',weight='bold',fontsize=12)\n",
    "plt.xticks(range(5),[10**x for x in range(5)])\n",
    "plt.yticks(range(5),[10**x for x in range(5)])\n",
    "plt.show()\n",
    "plt.plot(np.log10(1+customer_info_orders2['Revenue_2011_4']),\n",
    "         np.log10(1+customer_info_orders2['Revenue_2011_5']),'ro',markersize=0.5)\n",
    "plt.xlabel('mean revenue from month 3',weight='bold',fontsize=12)\n",
    "plt.ylabel('mean revenue from month 7-12',weight='bold',fontsize=12)\n",
    "plt.title('Month 4 vs future revenue',weight='bold',fontsize=12)\n",
    "plt.xticks(range(5),[10**x for x in range(5)])\n",
    "plt.yticks(range(5),[10**x for x in range(5)])\n",
    "plt.show()\n",
    "plt.plot(customer_info_orders2['svd_0'],1+customer_info_orders2['Revenue_2011_5'],'ro',markersize=0.5)\n",
    "plt.xlabel('mean revenue from month 3',weight='bold',fontsize=12)\n",
    "plt.ylabel('mean revenue from month 7-12',weight='bold',fontsize=12)\n",
    "plt.title('Month 4 vs future revenue',weight='bold',fontsize=12)\n",
    "#plt.xticks(range(5),[10**x for x in range(5)])\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "col = ['r','m','b','g'][::-1]\n",
    "percentile = [(0,1),(1,5),(5,20),(20,100)][::-1]\n",
    "size= [3,2,1,0.3][::-1]\n",
    "labels = ['Top 1% contributing 32% rev','1-5%, 18% Rev','5-20%, 25% Rev','20-100%, 25% Rev'][::-1]\n",
    "temp = customer_info_orders[customer_info_orders['mean_log_rev_train'] >0].sort_values('mean_log_rev_train').iloc[::-1].reset_index(drop=True)\n",
    "for i in range(4):\n",
    "    a,b = 0.01*len(temp)*percentile[i][0],0.01*len(temp)*percentile[i][1]\n",
    "    a,b = int(a),int(b)\n",
    "    plt.plot(temp['svd_0'].iloc[a:b],temp['svd_1'].iloc[a:b],'o',\n",
    "             color=col[i],markersize=size[i],label=labels[i])\n",
    "    print len(temp['svd_0'].iloc[a:b])\n",
    "plt.ylim(-0.25,0.4)\n",
    "plt.legend()\n",
    "plt.title('Looks like two clusters, inside and outside')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num = np.array([0,1])\n",
    "U2=U[:,num]\n",
    "D2=D[num]\n",
    "V2=V[num]\n",
    "\n",
    "Customer_embeddings = U2\n",
    "Product_embeddings = V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    plt.plot(range(len(V2[0,:])),V2[i,:],'ro',markersize=.5);\n",
    "    plt.xlabel('Product number, ordered by revenue generated',\n",
    "               fontweight='bold',fontsize=14)\n",
    "    plt.ylabel('%s embedding dimension'%(i+1),\n",
    "               fontweight='bold',fontsize=14)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2.groupby('StockCode_NR_int')['TotalRevenue'].apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get products with largest values for svd_0\n",
    "closest_to_inside = np.argsort(V2[0,:])[::1]\n",
    "stock_code_decribe = data2.groupby('StockCode_NR_int')['Description'].apply(np.unique).reset_index(drop=False)\n",
    "closest_pdts = closest_to_inside[:10]\n",
    "print 'products... largest sales'\n",
    "print stock_code_decribe[stock_code_decribe.StockCode_NR_int.isin(closest_pdts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get products closest to clusters inside\n",
    "cluster_inside = np.array([[-0.0125,0.1]])\n",
    "closest_to_inside = np.argsort(np.matmul(cluster_inside,V2)[0,:])[::-1]\n",
    "stock_code_decribe = data2.groupby('StockCode_NR_int')['Description'].apply(np.unique).reset_index(drop=False)\n",
    "closest_pdts = closest_to_inside[:10]\n",
    "print 'products...'\n",
    "print stock_code_decribe[stock_code_decribe.StockCode_NR_int.isin(closest_pdts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get products closest to clusters outside (impt customers)\n",
    "cluster_outside = np.array([[-0.0125,-0.1]])\n",
    "closest_to_outside = np.argsort(np.matmul(cluster_outside,V2)[0,:])[::-1]\n",
    "stock_code_decribe = data2.groupby('StockCode_NR_int')['Description'].apply(np.unique).reset_index(drop=False)\n",
    "closest_pdts = closest_to_outside[:10]\n",
    "print 'products...'\n",
    "print stock_code_decribe[stock_code_decribe.StockCode_NR_int.isin(closest_pdts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get products closest to clusters outside (impt customers)\n",
    "cluster_outside = np.array([[-0.125,0.1]])\n",
    "closest_to_outside = np.argsort(np.matmul(cluster_outside,V2)[0,:])[::-1]\n",
    "stock_code_decribe = data2.groupby('StockCode_NR_int')['Description'].apply(np.unique).reset_index(drop=False)\n",
    "closest_pdts = closest_to_outside[:10]\n",
    "print 'products...'\n",
    "print stock_code_decribe[stock_code_decribe.StockCode_NR_int.isin(closest_pdts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get products closest to clusters outside (impt customers)\n",
    "cluster_outside = np.array([[-0.125,-0.1]])\n",
    "closest_to_outside = np.argsort(np.matmul(cluster_outside,V2)[0,:])[::-1]\n",
    "stock_code_decribe = data2.groupby('StockCode_NR_int')['Description'].apply(np.unique).reset_index(drop=False)\n",
    "closest_pdts = closest_to_outside[:10]\n",
    "print 'products...'\n",
    "print stock_code_decribe[stock_code_decribe.StockCode_NR_int.isin(closest_pdts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stock_code_decribe = data2.groupby('StockCode_NR_int')['Description'].apply(np.unique).reset_index(drop=False)\n",
    "closest_pdts = closest_to_inside[:10]\n",
    "print 'products...'\n",
    "print stock_code_decribe[stock_code_decribe.StockCode_NR_int.isin(closest_pdts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.hist(dtest['mean_log_rev_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.hist(customer_info_orders['target']);\n",
    "plt.yscale('log');plt.yscale('log');plt.show();plt.close()\n",
    "plt.hist(customer_info_orders['target4']);\n",
    "plt.yscale('log');plt.yscale('log');plt.show();plt.close()\n",
    "plt.hist(customer_info_orders['target3']);\n",
    "plt.yscale('log');plt.yscale('log');plt.show();plt.close()\n",
    "plt.hist(model.predict(xgtest3));\n",
    "plt.yscale('log');plt.yscale('log');plt.show();plt.close()\n",
    "\n",
    "\n",
    "plt.plot(10**model.predict(xgtest2)-1,10**customer_info_orders['target5']-1,'ro',markersize=1);\n",
    "plt.xscale('log');plt.yscale('log');plt.xlabel('Prediction');plt.ylabel('Actual')\n",
    "plt.show();plt.close()\n",
    "plt.plot(10**model.predict(xgtest2)-1,10**customer_info_orders['target2']-1,'go',markersize=1);\n",
    "plt.xscale('log');plt.yscale('log');plt.xlabel('Prediction');plt.ylabel('Actual')\n",
    "plt.show();plt.close()\n",
    "#plt.plot(model.predict(xgtest3),customer_info_orders['target4'],'bo')\n",
    "#plt.plot(model.predict(xgtest3),customer_info_orders['target5'],'yo')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "df = customer_info_orders[['svd_'+str(x) for x in range(50) ]]\n",
    "for num in range(2,6):\n",
    "    kmeans = KMeans(n_clusters=num).fit(df)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    total_ss = np.sum((df.values-np.mean(df.values,0))**2)\n",
    "    unexplained_ss = 0\n",
    "    for i in range(num):\n",
    "        unexplained_ss += np.sum((df[kmeans.labels_==i].values-centroids[i])**2)\n",
    "    print unexplained_ss/total_ss\n",
    "    customer_info_orders['kmeans'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.hist(np.sum(df**2,1));plt.yscale('log');plt.xscale('log');plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#kmeans does not look sucesful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print model.get_fscore()\n",
    "#print predictors\n",
    "print sorted([(model.get_fscore()['f'+str(x)],predictors[x]) for x in range(len(predictors))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders[customer_info_orders['kmeans']!=0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders[customer_info_orders['kmeans']!=110].groupby('kmeans')['TotalRevenue'].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders[[x for x in  customer_info_orders.keys() if 'reve' in str(x).lower()]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#usinf predictions to predict instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders['predict']=model.predict(xgtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders['error'] = np.abs(model.predict(xgtest2)-customer_info_orders['target5'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(10** model.predict(xgtest2)-1,10**customer_info_orders[['target5']]-1,'ro',markersize=0.8);\n",
    "plt.yscale('log');plt.xscale('log');plt.show()\n",
    "plt.plot(customer_info_orders[['target5']],customer_info_orders[['error']],'ro',markersize=0.8);\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "customer_info_orders['target5_equal0'] = customer_info_orders['target5'] ==0 \n",
    "customer_info_orders.groupby('target5_equal0')['error'].apply(lambda x : (np.mean(x),np.std(x)))\n",
    "#possibly predict which custoemrs will fall out\n",
    "#or possibly try to see why large customers fall, Top 20 percent of customers,75.0 percent of profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.array(temp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#group of customers where the model is predicting poorly\n",
    "var = 'predict'\n",
    "customer_info_orders['target5_1dp'] = np.round(customer_info_orders['target5']*4,0)/4\n",
    "customer_info_orders['target5_1dp'] = (customer_info_orders['target5_1dp'] <3.75) * customer_info_orders['target5_1dp']  + (customer_info_orders['target5_1dp'] >3.75) *4 \n",
    "temp = customer_info_orders.groupby('target5_1dp')[var].apply(lambda x : (np.mean(x),np.std(x)/len(x)**.5,len(x))).reset_index(drop=False)\n",
    "print temp\n",
    "plt.errorbar(temp['target5_1dp'],[x[0] for x in temp[var]],yerr=[x[1] for x in temp[var]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# looking at the top20% for the first half and see which ones did not make it in second half\n",
    "#later\n",
    "customer_info_orders['Rev_first_half'] = np.mean(customer_info_orders[[x for x in customer_info_orders.keys() if 'Revenue_' in str(x)][:6]],1)\n",
    "customer_info_orders['Rev_second_half'] = np.mean(customer_info_orders[[x for x in customer_info_orders.keys() if 'Revenue_' in str(x)][6:]],1)\n",
    "customer_info_orders['Rev_future'] = (1*(customer_info_orders['Rev_second_half'] > customer_info_orders['Rev_first_half']))\n",
    "#customer_info_orders['Rev_future'] = np.log10(1+np.abs(customer_info_orders['Rev_future']))*np.sign(customer_info_orders['Rev_future'])\n",
    "\n",
    "\n",
    "colsA =  ['Revenue_2011_' + str(x) for x in [1,2,3,4,5]]+['Revenue_2010_12']\n",
    "customer_info_orders['mean_log_rev_firsthalf']= np.log10(1+np.mean(customer_info_orders[colsA].values,1))\n",
    "\n",
    "for i in ['Revenue_2011_' + str(x) for x in [1,2,3,4,5]]+['Revenue_2010_12']:\n",
    "    customer_info_orders['log_r'+i[1:]] = np.log10(1+customer_info_orders[i])\n",
    "\n",
    "predictors = ['log_r'+i[1:] for i in list(customer_info_orders.keys()[3:9])]+ ['mean_log_rev_firsthalf','constant']+\\\n",
    "                 list([x for x in customer_info_orders.keys() if 'svd' in str(x)]) [:00] \n",
    "\n",
    "target= 'Rev_future'\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#print predictors\n",
    "customer_info_orders['constant']=1\n",
    "customer_info_orders2 = customer_info_orders[customer_info_orders['Rev_first_half']!=0].reset_index(drop=True)\n",
    "#customer_info_orders2 = customer_info_orders2.sort_values(target).reset_index(drop=True)\n",
    "z = customer_info_orders2[['pdt_'+str(x) for x in range(100)]].describe().loc['mean']\n",
    "predictors += list(z[z>0.03].index)\n",
    "dtrain = customer_info_orders2\n",
    "train_id = [x for x in range(len(dtrain)) if x%5!=0]\n",
    "test_id = [x for x in range(len(dtrain)) if x%5==0]\n",
    "dtrain1 = customer_info_orders2.iloc[train_id].reset_index(drop=True)\n",
    "dtrain2 = customer_info_orders2.iloc[test_id].reset_index(drop=True)\n",
    "#print customer_info_orders2[[target,'Rev_first_half','Rev_second_half']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(customer_info_orders2[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "for alpha in [0.02,0.025,0.03,0.04][:1]:\n",
    "    if alpha!=0.0511:\n",
    "        dtrain_scaled = (dtrain[predictors]-np.mean(dtrain[predictors].values,0))/np.std(dtrain[predictors].values,0)\n",
    "        dtrain1_scaled = (dtrain1[predictors]-np.mean(dtrain1[predictors].values,0))/np.std(dtrain1[predictors].values,0)\n",
    "        dtrain2_scaled = (dtrain2[predictors]-np.mean(dtrain1[predictors].values,0))/np.std(dtrain1[predictors].values,0)\n",
    "        dtrain_scaled['constant'] = 1\n",
    "        dtrain1_scaled['constant'] = 1\n",
    "        dtrain2_scaled['constant'] = 1\n",
    "        predictors_noNan = np.array(predictors)[~dtrain1_scaled.describe().loc['mean'].isnull()]\n",
    "        model = sm.GLM(dtrain1[target],dtrain1_scaled[predictors_noNan],family=sm.families.Binomial()).fit_regularized(alpha= alpha)\n",
    "        predictors_nonZero = list(predictors_noNan[model.params!=0])\n",
    "        model_unbias = sm.GLM(dtrain1[target],dtrain1_scaled[predictors_nonZero],family=sm.families.Binomial()).fit()\n",
    "        model_unbias_full = sm.GLM(dtrain[target],dtrain_scaled[predictors_nonZero],family=sm.families.Binomial()).fit()\n",
    "        print  alpha,len(predictors_nonZero)\n",
    "        print 'train R2',roc_auc_score(dtrain1[target],model_unbias.predict(dtrain1_scaled[predictors_nonZero]))\n",
    "        print 'test R2',roc_auc_score(dtrain2[target],model_unbias.predict(dtrain2_scaled[predictors_nonZero]))\n",
    "        print model_unbias_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# products associated with improved spending in future\n",
    "print 'products associated with positive future revenue...'\n",
    "print model_unbias_full.params[model_unbias_full.params>0]\n",
    "stock_code_decribe = data2.groupby('StockCode_NR_int')['Description'].apply(np.unique).reset_index(drop=False)\n",
    "pos_params = model_unbias_full.params[model_unbias_full.params>0]\n",
    "pos_params = [int(x.split('_')[1]) for x in pos_params.index if 'pdt' in x]\n",
    "print 'products...'\n",
    "print stock_code_decribe[stock_code_decribe.StockCode_NR_int.isin(pos_params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# products associated with improved spending in future\n",
    "print 'products associated with negative future revenue...'\n",
    "print model_unbias_full.params[model_unbias_full.params<0]\n",
    "stock_code_decribe = data2.groupby('StockCode_NR_int')['Description'].apply(np.unique).reset_index(drop=False)\n",
    "neg_params = model_unbias_full.params[model_unbias_full.params<0]\n",
    "neg_params = [int(x.split('_')[1]) for x in neg_params.index if 'pdt' in x]\n",
    "print 'products...'\n",
    "print stock_code_decribe[stock_code_decribe.StockCode_NR_int.isin(neg_params)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# looking at top 20% customers which consistute 75% revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# looking at the top20% for the first half and see which ones did not make it in second half\n",
    "#later\n",
    "customer_info_orders['Rev_first_half'] = np.mean(customer_info_orders[[x for x in customer_info_orders.keys() if 'Revenue_' in str(x)][:6]],1)\n",
    "customer_info_orders['Rev_second_half'] = np.mean(customer_info_orders[[x for x in customer_info_orders.keys() if 'Revenue_' in str(x)][6:]],1)\n",
    "customer_info_orders['Rev_future'] = (1*(customer_info_orders['Rev_second_half'] > customer_info_orders['Rev_first_half']))\n",
    "#customer_info_orders['Rev_future'] = np.log10(1+np.abs(customer_info_orders['Rev_future']))*np.sign(customer_info_orders['Rev_future'])\n",
    "\n",
    "\n",
    "colsA =  ['Revenue_2011_' + str(x) for x in [1,2,3,4,5]]+['Revenue_2010_12']\n",
    "customer_info_orders['mean_log_rev_firsthalf']= np.log10(1+np.mean(customer_info_orders[colsA].values,1))\n",
    "\n",
    "for i in ['Revenue_2011_' + str(x) for x in [1,2,3,4,5]]+['Revenue_2010_12']:\n",
    "    customer_info_orders['log_r'+i[1:]] = np.log10(1+customer_info_orders[i])\n",
    "\n",
    "predictors = ['log_r'+i[1:] for i in list(customer_info_orders.keys()[3:9])]+ ['mean_log_rev_firsthalf','constant']+\\\n",
    "                 list([x for x in customer_info_orders.keys() if 'svd' in str(x)]) [:00] \n",
    "\n",
    "target= 'Rev_future'\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#print predictors\n",
    "customer_info_orders['constant']=1\n",
    "customer_info_orders2 = customer_info_orders[customer_info_orders['Rev_first_half']!=0].reset_index(drop=True)\n",
    "#customer_info_orders2 = customer_info_orders2.sort_values(target).reset_index(drop=True)\n",
    "\n",
    "\n",
    "z = customer_info_orders2[['pdt_'+str(x) for x in range(50)]].describe().loc['mean']\n",
    "predictors += list(z[z>0.05].index)\n",
    "customer_info_orders2 = customer_info_orders2.sort_values('TotalRevenue').iloc[-2*135:]\n",
    "dtrain = customer_info_orders2\n",
    "train_id = [x for x in range(len(dtrain)) if x%5!=0]\n",
    "test_id = [x for x in range(len(dtrain)) if x%5==0]\n",
    "dtrain1 = customer_info_orders2.iloc[train_id].reset_index(drop=True)\n",
    "dtrain2 = customer_info_orders2.iloc[test_id].reset_index(drop=True)\n",
    "#print customer_info_orders2[[target,'Rev_first_half','Rev_second_half']]\n",
    "plt.hist(customer_info_orders2[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictors_nonZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import statsmodels.api as sm\n",
    "for alpha in [0.07,][:]:\n",
    "    if alpha!=0.0511:\n",
    "        dtrain_scaled = (dtrain[predictors]-np.mean(dtrain[predictors].values,0))/np.std(dtrain[predictors].values,0)\n",
    "        dtrain1_scaled = (dtrain1[predictors]-np.mean(dtrain1[predictors].values,0))/np.std(dtrain1[predictors].values,0)\n",
    "        dtrain2_scaled = (dtrain2[predictors]-np.mean(dtrain1[predictors].values,0))/np.std(dtrain1[predictors].values,0)\n",
    "        dtrain_scaled['constant'] = 1\n",
    "        dtrain1_scaled['constant'] = 1\n",
    "        dtrain2_scaled['constant'] = 1\n",
    "        predictors_noNan = np.array(predictors)[~dtrain1_scaled.describe().loc['mean'].isnull()]\n",
    "        model = sm.GLM(dtrain1[target],dtrain1_scaled[predictors_noNan],family=sm.families.Binomial()).fit_regularized(alpha= alpha)\n",
    "        predictors_nonZero = list(predictors_noNan[model.params!=0])\n",
    "        model_unbias = sm.GLM(dtrain1[target],dtrain1_scaled[predictors_nonZero],family=sm.families.Binomial()).fit()\n",
    "        model_unbias_full = sm.GLM(dtrain[target],dtrain_scaled[predictors_nonZero],family=sm.families.Binomial()).fit()\n",
    "        print  alpha,len(predictors_nonZero)\n",
    "        print 'train R2',roc_auc_score(dtrain1[target],model_unbias.predict(dtrain1_scaled[predictors_nonZero]))\n",
    "        print 'test R2',roc_auc_score(dtrain2[target],model_unbias.predict(dtrain2_scaled[predictors_nonZero]))\n",
    "        print model_unbias_full.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
